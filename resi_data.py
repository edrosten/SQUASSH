from typing import List, Any, Tuple
import yaml
import h5py
import numpy as np
import torch
import tqdm
import tifffile

import render


# Paper
# https://www.nature.com/articles/s41586-023-05925-9#Sec6
# https://zenodo.org/records/7795826

def _load_data(file_root: str)->Tuple[List[torch.Tensor], List[torch.Tensor]]:

    # This is a bit sketchy. Reading the Picasso data files.
    # As far as I can tell, the x/y units are pixels and Z is in micrometers
    # So, find the pixel size and multiply by pixelsize.
    #
    # Picasso metadata is a multidocument YAML file. The pixel size on the sample
    # (i.e. camera pix size / objective mag) is in one section. Sections appear to
    # be identified by "Generated by", but there are duplicates.
    with open(file_root + ".yaml", encoding="utf-8") as y:
        metadata = list(yaml.safe_load_all(y))
        pixel_sizes = [ b['Pixelsize'] for b in metadata if "Pixelsize" in b and b["Generated by"] == "Picasso Localize"]

        if len(pixel_sizes) != 1:
            raise RuntimeError(f"Found {len(pixel_sizes)} pixel sizes reading {file_root}.yaml")

        pixel_size = pixel_sizes[0]

    data=h5py.File(file_root + ".hdf5")

    locs = np.array(data['locs'])


    xind: int = locs.dtype.names.index('x') # type: ignore
    yind: int = locs.dtype.names.index('y') # type: ignore
    zind: int = locs.dtype.names.index('z') # type: ignore
    
    # Obnoxiously, there the field name for grouping is not consistent
    group_name = ""
    for gn in ["group_input", "group"]:
        if gn in locs.dtype.names: #type: ignore
            if group_name:
                raise RuntimeError("Multiple group names")
            group_name = gn

    gind: int = locs.dtype.names.index(group_name) # type: ignore

    num_groups = max(i[gind] for i in locs)+1
    # Group by, well, group
    groups: List[Any] =[ [] for _ in range(num_groups) ]
    for i in locs:
        groups[i[gind]].append((i[xind]*pixel_size,i[yind]*pixel_size,i[zind]))
    
    out: List[torch.Tensor] = []
    mean: List[torch.Tensor] = []

    for v in groups:
        # Centre the data
        t = torch.tensor(v)
        m = torch.mean(t,0)
        t -= m
        out.append(t)
        mean.append(m)

    return out, mean

def load_3d_with_means()->Tuple[List[torch.Tensor], List[torch.Tensor]]:
    '''Load the dataset'''
    file_root="data/resi/Figure2,EDF06,EDF07/RESI/RESI result/RESI_R1,R2,R3,R4_multi"
    return _load_data(file_root)

def load_3d()->List[torch.Tensor]:
    '''Load the dataset'''
    return load_3d_with_means()[0]



def load_3d_PAINT_with_means()->Tuple[List[torch.Tensor], List[torch.Tensor]]:
    '''Load the paint r1,r2,r3,r4_apicked dataset'''
    file_root="data/resi/Figure2,EDF06,EDF07/DNA-PAINT/DNA-PAINT_imaging/DNA-PAINT_R1,R2,R3,R4_apicked"
    return _load_data(file_root)

def load_3d_PAINT()->List[torch.Tensor]:
    '''Load the paint r1,r2,r3,r4_apicked dataset'''
    return load_3d_PAINT_with_means()[0]


if __name__ == "__main__":
    def _do()->None:
        data = load_3d()
        
        device = torch.device("cuda:0" if torch.cuda.is_available() else "cpu")
        data = [d.to(device).half() for d in data]

        rendered: List[List[torch.Tensor]] = [
                render.render_multiple_scale(
                    centres=d.unsqueeze(0),
                    sigma_xy_nm = 2 * torch.ones(1, device=device),
                    weights = torch.ones(1, d.shape[0], device=device),
                    nm_per_pixel_xy=1.5,
                    z_scale=2,
                    xy_size=128,
                    z_size=64
                ) for d in tqdm.tqdm(data)]


        imgs=[]

        border=2 
        for d in rendered:
            width = sum(i.shape[-1] for i in d) + border * (len(d))
            height = max(i.shape[-2] for i in d)

            img = torch.zeros(3, height, width)
            #Set bg to blue
            img[2,:,:] = 1
            
            h=border//2
            for i in d:
                i /= i.max()
                i = i.squeeze(0).squeeze(0)
                img[0,0:i.shape[0], h:h+i.shape[1]] = i
                img[1,0:i.shape[0], h:h+i.shape[1]] = i
                img[2,0:i.shape[0], h:h+i.shape[1]] = i
                h += i.shape[1] + border
            
            img *=255
            img = img.permute(1, 2, 0)
            img = img.char()
            imgs.append(img)

        tifffile.imwrite('hax/staq.tiff', torch.stack(imgs, 0).numpy())



    _do()

